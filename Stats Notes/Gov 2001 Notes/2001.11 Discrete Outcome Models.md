---
date updated: 2021-10-22 15:49

notetype: "Math Class Note"
cssclass: math-class-note

tags: 
- '#types/classes/stats/models'
---

# [[2001.11 Discrete Outcome Models]]
[[Gov 2001]]

Basic idea:
- we want to represent something that takes on some set of values
- good for censored models - want to cut off some values

## Ordered probit
- Stochastic component: $Y^* \sim \text{STN}(y_i^*|\mu_i)$ where systematic component is  $\mu_i = X_i\beta$
- If $Y^*$ is observable, that's a only-mu linear regression

But we don't know $Y^*$. We instead have an observation mechanism, where $Y_i$ is ordinal - if $y^*_i$ is in a certain interval, $y_i$ takes on the according value $j$ (thresholds being the parameters $\tau_j =\tau_1, \tau_2, \ldots$); this is another part of the stochastic component
- eg. imagine a sliding scale of civil conflict - protest, riots, guerilla warfare, organized revolution. We don't know what the thresholds are, or how far apart they are. We may want that information, as well as to predict which will occur
- You can use this with a Likert scale but the taus will be probably more evenly spaced?


#### Estimating Ordered Probit
We can first estimate the $\beta$, which tells you only about $X$ and $Y^*$ - $\beta$ is in units like a $z$ score

$$\begin{aligned}
\text{Pr}(Y_i = j) &= \text{Pr}(\tau_{j-1} \leq Y^*_i \leq \tau_j)\\
&= \int_{\tau_{j-1}}^{\tau_j}\text{STN}(y^*|\mu_i) \;dy_i^*\\
&= F_{STN}(\tau_j|\mu_i) - F_{STN}(\tau_{j-1}|\mu_i) \\
&= F_{STN}(\tau_j|X_i\beta) - F_{STN}(\tau_{j-1}|X_i\beta) \\
\end{aligned}$$

where $F_{STN}$ is the CDF of the stylized normal. 

We can then use the independence assumption to say that $\text{Pr}(Y) = \prod_{i=1}^n \text{Pr}(y_i  = j)$
Then the LL is $\ln L(\beta, \tau|Y) = \sum \ln \text{Pr}(Y_i = j)$
NOTE: we've had to assume here that none of these probabilities is $0$. But the stylized normal is positive everywhere

To have the right degrees of freedom when optimizing you have to pick one of the $\tau$s and set it to $0$. Also you have to make sure that the optimizations take on the right values. 
#### Interpreting Coefficients
- $\beta$ is  the $z$ score effect of $X$ on $Y^*$. 
- $\widehat{\text{Pr}(Y_i |X)}$ for all $J$ sum up to $1$
- One first difference affects $J$ probabilities and when one goes up, one of the others goes down

Ternary example: UK Cons, Labour, other parties/'Alliance'
- Ordered probit with 3 probabilities
- Viz: a triangle. Three axes at 60 degrees, each constituency is a tuple.
- Triangle divided into three equal spearhead shapes denoting which party has majority 
![[Pasted image 20211022162847.png]]
- This is better than a surface plot because there really are only two free parameters

## Grouped Uncorrelated Binary Model

- We only observe the _sum_ of iid Bernoulli trials for each observation
- E.g. a survey q: ask $n$ people, how many times did you read the newspaper last week \[ though this is hardly iid ... \]

Model:
$Y_i \sim \text{Binomial}(y_i|\pi_i)$, where $\pi_i$ is the same for all the trials. $\pi_i = 1/(1 + \exp(-X\beta))$; and $E(Y_i) = N_i \pi_i$ where $N$ is the number of trials. + independence 

Same inferential goal as binary logit. If we had individual results we'd want those $\pi$. 
- Maximize LL and save $\betahat$ and $\hat{V}(\betahat)$. 
- Draw $\betahat$ from the usual multivariate normal
- Choose $X_c$ and calculate simulations of $\tilde{\pi}_c = 1/(1 + \exp(-X_c \tilde{\beta})$
- You can then use those values of $\tilde{\pi_c}$ to create other QOIs if you want


## Grouped Correlated Binary Model

Problems with the uncorrelated models: 
1) the days reading the newspaper are not iid within $i$
2) $V(Y_i) = \pi_1(1 - \pi_i)/N_i$ with no $\sigma^2$. 

These are observationally the same. If there is non-independence, the variance will deviate from the above. 


New model: Extended Beta-Binomial Model
Have a dispersion parameter $\gamma$. 
$Y_i \sim f_{ebb}(y_i | \pi_i, \gamma))$, $\pi_i = 1/(1+ \exp(-X_i \beta)$. 

Ebb PDF: 
$$\begin{aligned}
f_{ebb}(y_i |\pi_i, \gamma) &= \text{Pr}(Y_i = y_i |\pi_i, \gamma, N)\\ 
&=\frac{N!}{y_i!(N-y_i)!}\prod_{j=0}^{y_i-1} (\pi_i + \gamma j) \times \\
& \qquad \, \, \, \, \prod_{j=0}^{N - y_i - 1}(1 - \pi_i + \gamma j) \times \\& \qquad 1/\prod_{j=0}^{N-1}(1 + \gamma j)\\
\end{aligned}$$

What the hell is this?
- It all corresponds to the binomial PDF, sort of.
- First factor is $N \choose y_i$. Suppose you read the newspaper 4 times this week. This could hae been MTWTh, TWThF, and so on. 
- Second factor is the probability that you read the newsaper $y_i$ times, correcting for the variance. 
- Third factor is the probability that you don't read the newspaper the rest of the days.
- The denominator is correcting the whole thing for the correlations between the variables?

Simulate as usual going through $\pi$. 


## Event count models

- Units of analysis could be over time, over individuals, etc. 
- Event count is the number of events for some observation $i$ 
- No upper limit 

Examples: 
- \# of triplets born in norway each half-decade
- annual  \# of appointments to supreme court 
- You might think this is a poisson distribution! And that's what the literature believes. 
- But just because it fits a poisson doesn't mean it's random...  

Poisson fundamental idea: you show up after some interval has passed and count how many times X event has happened from start of interval to your arrival 
- No two events can happen at the same time
- Markov independence: Probability of event at time $t$ given all events before time $t$ is independent of $t$. 

$Y_i \sim \text{Poisson}(y_i|\lambda_i)$, $\lambda_i = \exp(X_i \beta)$, independence

Issues:
- markov independence assumption matters
- no variance parameters
- If this model is used wrongly, SE and fit are wrong


#### Interpreting results

Derivative method: $\frac{\partial \lambda_i}{\partial X_i^1} = \exp(x_i \beta)\beta_1 = \lambda_i\beta_1$
- Remember from bernoulli logit - this is a quick way to interpret results. 
- How much does the expected number of events change as $x_i$ changes - it's $\lambda_i \beta_1$. This comes from the exponential functional form?
- So $\ybar \beta$ gives you an approximate linearized effect 

Variance under misspecification
- Under the poisson, $V(Y_)