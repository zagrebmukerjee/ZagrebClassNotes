---
date updated: 2021-11-14 17:57

notetype: "Math Class Note"
cssclass: math-class-note

tags: 
- '#classes/stats/causalinf'
---

# [[2001.16 Matching Methods]]


Goal of matching is to find hidden randomized experiments inside observational data

Two types of experiments:
- Complete randomization
- Fully blocked: can randomize within strata of known explanatory variables. Thus $\Delta_{T_X}$ is exactly 0. So fully blocked dominates complete randomization for imbalance, model-dependence, power, efficiency, bias, research costs, robustness

#### Robustness example
- rollout of mexican national healthcare plan
- Randomize communities in which healthcare was rolled out 
- Most large-scale public policy evaluations fail, because politicians interfere with assignment of treatment
- SO need robustness to politics :)

Matched pairs are the best kind of blocking. Find communities A and B with as-close-to-identical characteristics as possible. Then pick one to get the treatment. Politicians can pick one and it's still fine because you can drop the pair they are messing with and avoid tainting the rest of the data

Standard errors _much_ smaller

### Matching methods

Goals of matching methods:
- Propensity score matching: goal is complete randomization
- Other methods: fully blocked experiment. So PSM dominated by other methods
- it gets worse for PSM


#### Mahalanobis Distance Matching

1. Preprocess
	1. Distance $(X_c, X_t)$ is $\sqrt{(X_c-X_t)'S^{-1}(X_c - X_t)}$
	2. This is the mahalanobis distance - is standardized Euclidean distance 
		1. $X_c$ is control covariates; $X_t$ is treatment covariates. 
		2. Match each treated unit to the nearest control unit
			1. Baseline: matching is greedy - grab nearest neighbor.
			2. there are optimizations
		3. Control units are not reused. If unused they are pruned
		4. Prune matches if distance > _caliper_ - some threshold distance (this isn't matched enough)
		5. Many adjustments allowed
2. Estimation: difference in means or model
3. Interpretation
	1. Distance metric is trying to compare apples and oranges (the different covariates). 
	2. The standardization is based on sample standard deviation - but this is subject to sampling errors. 
4. Mahalanobis is for methodologists :) use the euclidean distance for many applications
5. Best case - every treated has a control very close by. For every treated person you have a counterfactual


#### Coarsened Exact Matching

1. Preprocess
	1. Temporarily coarsen explanatory variables as much as possible - i.e. binning
	2. Apply exact-matching method to the coarsened X - sort observations into strata
	3. prune any strata with 0 control or 0 treatments
	4. pass on original units in their strata (without the pruned ones)
2. Estimation: Difference in means or model
	1. Weight controls in each stratum to equal treateds
3. Interpretation - we are exact-matching between bins
4. you can increase the size of the bins, but that reduces the value of matching - leaves more model dependence on the table. This is a _substantive_ decision

#### Propensity scores

Unlike other methods, approximates a completely random experiment

1. Preprocess
	1. Reduce $k$ elements of $X_i$ to a single scalar 
		1. Run a logit $\pi_i =$ Pr$(T_i = 1|X) = \frac{1}{1+ \exp[{-X_i\beta}]}$
		2. This thing $\pi_i$ is the propensity to be treated
	3. Distance $X_c, X_t$ = $|\pi_c - \pi_t|$. 
	4. Simplest version is to match to nearest unit without reusing
	5. prune unmatch, prune if a pair is too far apart
2. Estimation - difference in means or a model
3. Interpretation - distance is differential probability of treatment. What exactly does that mean? Intuitively, the logit regression is picking up variables that are related to treatment. 
	1. When one variable has a big impact on Y, you want to control for it for sure. But the PS measure doesn't capture that
4. Best case, every treatment unit has a nearly-identical control unit. 
	1. Suppose every propensity score is the same - i.e. actual random assignment!
	2. But then matching is impossible!
	3. So pruning is random
		1. Random pruning increases imbalance! If you remove half the people in a classroom, expected distance between students goes up. 
		2. imagine you have male treated, female treated, male control, female control. If you randomly prune, half the time you'll make yourself sex-imbalanced. 
		3. Very general result
5. PSM has low standards. Sometimes helps. Never optimizes
6. PSM 'Paradox': When you do better, you do worse. When PSM approximates complete randomization, it's pruning randomly: that means it's increasing imbalance
7. If the data have no good matches, you're still screwed. Can't do matching without matches
8. Doesn't PSM solve curse of dimensionality??? NO... dimensionality is not a problem. It's something you need to deal with. PSM paradox gets worse if there are more covariates



