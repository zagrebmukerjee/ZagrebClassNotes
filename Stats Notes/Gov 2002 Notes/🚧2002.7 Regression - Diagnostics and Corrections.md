---
date updated: 2022-04-19 13:00

notetype: "Math Class Note"
cssclass: math-class-note

tags: 
- '#types/classes/stats/regression'
- '#status/ðŸš§'
---

# [[ðŸš§2002.7 Regression - Diagnostics and Corrections]]


## Non-normality of Errors

If the true errors are not normal, we may want to know. This would mean that our small-sample performance is worse - we don't get the guarantees that come with consistency and asymptotic normality - meaning $p$ values, confidence intervals and other metrics of the sampling distribution will be misstated. 

It's hard to see $u$ - you have to estimate it with $\uhat$. 

#### Residuals, analytically

$$\begin{aligned}
\uhat &= y - X\betahat \\
&= y - X(X'X)^{-1}X'y \\
&= y - Hy\\
&= (I - H)y \\
\end{aligned}
$$
Here, we've created a new matrix $H$, where $H = X(X'X)^{-1}X'$, where $Hy = \yhat$. $H$ is called the <font color=gree>projection matrix</font>, or hat matrix. 

We also have $(I-H)$, such that $(I-H)y$ is the residuals. We call this $M$ - the <font color=gree>annihilator matrix</font> - which turns $y$ into its residuals. 

$H$ and $M$ are both symmetric. They are both *idempotent*: $HH = H, MM = M$.

We can use the above to get a sense of the residuals as an estimate of the true errors:

$$
\begin{aligned}
\uhat &= My \\
&= M(X\beta + u)\\
&= MX\beta + Mu \\
&= X\beta - X(X'X)^{-1}X'X\beta + Mu \\
&= X\beta - X\beta + Mu \\
&= Mu
\end{aligned}
$$

This tells us that the residuals are a linear function of the true errors. So we can look at the normality of the residuals. 


To look at that, we standardize the residuals to $z$ scores, and then 'studentize' them. This lets us make e.g. a QQ plot of the residuals vs the $t$ distribution they should follow. 